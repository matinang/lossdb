---
output: html_document
---
<!--
%\VignetteEngine{knitr::docco_linear}
%\VignetteIndexEntry{Introduction to lossdb}
-->

```{r, echo = FALSE, message = FALSE}
library(lossdb)
knitr::opts_chunk$set(
  comment = "#>",
  tidy = FALSE)
```

# Introduction to lossdb

The goal of this document is to introduce the basic tools `lossdb` provides, and to walk through a realistic example using the `lossdb` package.  This vignette and package are still in their early stages of development...

## Background: Actuaries and Insurance Loss Data

The largest and most important data sets actuaries commonly work with are data sets describing the value and nature of insurance losses.  These data sets are often provided on a "by claim" basis (i.e. each row represents a claim and each column a variable).  These "by claim" data data sets, which I will call "loss data", are provided in a different format by every company, and often times many different formats by the same company.  A thorough combing of the loss data is often necessary to determine what each column is communicating and what columns are relevant to the analysis.  Additionally there are almost always errors that need to be addressed.  Understanding the underlying structure of the columns and ways to identify common errors can significantly improve the overall analysis process.

Loss data will often have many columns representing different dollar amounts.  I refer to the columns representing dollar amounts as the "value"
columns.  All the information contained in the value columns can be categorized into 4 different groups without loosing any information.  Each of these 4 groups can contain as many columns as neccessary to contain a full description of the data.  The 4 groups containing all the information in the value columns are:

* paid - actual amounts already paid
* incurred - amounts incurred (i.e. total amount expected to be paid by the insurance company before the claim is closed)
* paid_recovery - actual paid reimbursements (e.g. amount under deductible)
* incurred_recovery - incurred reimbursements

Note:  A case reserve amount could be used in place of incurred.  Either one would work.

All the other columns included in loss data provide some type of description of the claim (e.g. claimant name, whether the claim is open or closed, etc.).  I refer to all of these columns as "description" columns.  There can be any number of description columns.

`lossdb` is designed to utilize the fundamental underlayings of loss data to make loss data easier to work with. 

## Motivation

I want to make reproducible actuarial reports in R.  Getting unclean data ready for analysis is a pain in the ass, and once the data is clean it is nice to have it in some kind of a standard format so you can do similar things to data whenever you get it into that format... enter `lossdb`

The goal of the `lossdb` package is to provide standard functions for manipulating and visualizing loss data. `lossdb` provides a standard means of storing your claims data so you can use the same set of functions (defined by `lossdb`) to automate many repetetive tasks and ultimately create reproducible reports that are generated directly from the original loss data.

When using R one can easilty improve the flexibility of their reports by maintaining access to all the original claim detail (i.e. each report can be generated from the original claim data as opposed to a summary and a bunch of copy and pastes of the original claim data). This can be a huge time saver if you need to go back and change an origninal assumtion of your report.  Additionally generating reports from the original data reduces and provides confidence that the numbers in your report are in fact correct.  

In summary, `lossdb` provides a standard format for storing loss data and provides a set of functions specific to that standard format.  The fact that the entire report can be done in R is what makes it more easily reproducible.  `lossdb` just makes it a little easier to go from raw data to a final report in R.

## Getting Started

The standard format `lossdb` uses to store claim loss data is the S3 class `loss_df`.  A `loss_df` is created using the `loss_df()` function.  A `loss_df` holds and cetegorizes loss information on a claim or occurence basis, and is flexible enough to handle data that is categorized and organized differently from company to company. 

The rest of this vignette will guide you through an example using `lossdb`.  The example will proceed as follows:
* Taking a data set (`losses`) in a format resembling how data may be provided by an insurance company, and transforming that data set into a `loss_df` object that contains and organizes all the information relevant to the analysis.
* Reviewing the `loss_df` for errors and probelm areas.
* Performing statistical reserving techniques on the `loss_df`.
* Create a PDF document of the results complete with graphics, tables, and text.

View the structure of the uncleaned `losses` data frame using the `str` function:
```{r, eval = FALSE}
str(losses)
```
There are many columns that are not relevant to our analysis, and some transformations must be applied to the data to get all the necessary information out of the losses data frame.  Let's get started.

### Format the data 

The `loss_df()` function takes the uncleaned data frame as its first formal argument.  All additional arguments are used to categorize the columns in the loss df.  There are two main categories that a loss_df column can fall into: required (general information about the claim) and loss values (loss dollar amounts and claim descritions)

* Required: These categories provide all the necessary claim detail other than the actual loss values. A `loss_df` is required to have the following columns:
  * origin: numeric - the time period in which the claim originated
  * dev: numeric - the development stage of the claim at the relevant evaluation_date

* Loss Values: All loss values must be numeric. Each category can contain as many columns as necessary, but avoid double counting (i.e. do not have one category for paid losses, one for paid expenses, and one for total paid losses and expenses.  Just supply the paid losses and paid expenses categories separately or the sum of paid losses and paid expenses).  All loss values must fall into 1 of the following 5 categories:
  * paid: paid amounts
  * incurred: incurred amounts
  * paid_recovery: paid recovery amounts
  * incurred_recovery: incurred recovery amounts
  * desc: miscellaneous descriptive amounts

Next the dplyr package is used to clean the `losses` data so it conforms to the format required to make a `loss_df`.  If you are not familiar with the dplyr package see the [dplyr introduction vignette](http://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html)
```{r, message = FALSE}
library(dplyr)
# create origin and dev column
losses <- mutate(losses, origin = as.numeric(substr(fiscal_year_desc, 1, 4)), 
                 evaluation_year = as.numeric(format(as.Date(evaluation_date, "%Y-%m-%d"), "%Y")),
                 dev = evaluation_year - origin) 

# group claims by occurence
# often necessary when excess reinsurance is applied on an occurence basis
# rather than on a claims basis.
occurences <- losses %>%
  group_by(claim_number, dev, origin) %>%
     summarise(claim_cts = n(),
               payment_amount = sum(payment_amount), # paid loss & ALAE
               incurred_amount = sum(reserve_amount), # incurred loss & ALAE
               paid_expense = sum(X4_exp_payment), # paid ALAE
               incurred_expense = sum(X4_exp_reserve), #incurred ALAE
               sal_sub_paid = sum(payment_no_reserve_a), # salvage and subrogation
               sal_sub_incurred = sum(payment_no_reserve_a)
              )

# create relevant loss values columns
occurences <- mutate(occurences,
                    paid_loss = payment_amount - paid_expense,
                    incurred_loss = incurred_amount - incurred_expense,
                    paid_excess250 = max(payment_amount - sal_sub_paid - 250000, 0),
                    incurred_excess250 = max(incurred_amount - sal_sub_incurred - 250000, 0)) 
```

The above code does not use the `lossdb` package.  All that code did was prepare the data for use with the `lossdb` package (often a time consuming task esprecially the first time working with a fresh data set).

Now that we have all the necessary columns, we can create the `loss_df` object.
```{r}
# create loss_df object
mydf <- loss_df(occurences, id = "claim_number",
                             origin = "origin",
                             dev = "dev", 
                             paid = c("paid_loss", "paid_expense"),
                             incurred = c("incurred_loss", "incurred_expense"),
                             paid_recovery = c("paid_excess250", "sal_sub_paid"),
                             incurred_recovery = c("incurred_excess250", 
                                                   "sal_sub_incurred"),
                             desc = "claim_cts"
                 )
head(mydf[, 1:6])
```

Each column has an attribute specifying the `type` of loss detail that the column contains.  The `type` was defined by the argument the column was supplied to in the `loss_df()` function (i.e. `paid_loss` and `paid_expense` are of `type` `paid`).

### Review the data

Now we can use the `lossdb` package to review the data.  Let's start by seeing a summary of the most recent loss detail summarized by origin period.

```{r}
summary(mydf)
```

We can look at the data at an older evaluation date by specifying the `evaluation_date`

```{r}
summary(mydf, evaluation_date = "2012")
```

Note: the default `evaluation_date` if none is supplied to the `loss_df` function is set to the `origin` period plus the `dev`. (e.g.) The `evaluation_date` for all claims in origin year 2010 at their first `evaluation_date` would be 2011.

and the build in bar chart representation of the data...

```{r}
plot(mydf)
```

and plotted at an alternative `calendar`

```{r}
plot(mydf, calendar = "2012")
```

We can return a data frame of all the claims that have experienced a change from one evaluation date to another by using the `claim_changes()` function:

```{r}
# specify the loss amount values you want to see the changed claims for 
mychanges <- claim_changes(mydf, calendar1 = "2013", calendar2 = "2012",
                            values = c("paid_loss", "claim_cts"))
head(mychanges)
```

`mychanges` is a data frame consisting of all the claims in which there was a change in the "paid _ loss" column from 2012-06-30 to 2013-06-30.  You can now browse through the changed claims to spot obvious problems with the new data.  For example we may want to check that there are no missing claims (i.e. no claims that were in the data at the last `evaluation_date` that are no longer in the data)

```{r}
# check for missing claims
mychanges[, mychanges$claim_cts_change < 0]
```

We may also want to check if the `paid_loss` category decreased for any claims.

```{r}
# check for claims in which paid_loss decreased
mychanges[, mychanges$paid_loss_changes < 0]
```

There are no missing claims or claims with a decrease in `paid_loss`.  After this quick review it appears that new data are reasonable.  Next we can project some ultimate losses. 

### Create Projections

Before a projection is made we must specifiy the loss amounts we wish to project (e.g. paid loss & ALAE gross of all recoveries, paid loss & ALAE net of all recoveries, medical only paid loss & ALAE gross of all recoveries, etc.).  The `retain` function specifies the values to be projected.

```{r}
# include recovery detail by category: `sal_sub_paid` and `paid_excess250`
value2project <- retain(mydf, value = "paid", recovery = c("paid_excess250", "sal_sub_paid"))
head(value2project)
```

Now the `ChainLadder` package can be used to make projections.  